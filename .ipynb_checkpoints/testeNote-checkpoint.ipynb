{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Reg_Models import RegModels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn import model_selection\n",
    "import xgboost\n",
    "\n",
    "data = pd.read_csv(\"./dados/FRA3-FRA6_cleaned_feature_engineered.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_scaled_dataset(X, y):\n",
    "    from sklearn.model_selection import cross_val_score, train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X_scaled_train = pd.DataFrame(std_scaler.fit_transform(\n",
    "        X_train), columns=X_train.columns, index=X_train.index)\n",
    "    X_scaled_test = pd.DataFrame(std_scaler.transform(\n",
    "        X_test), columns=X_train.columns, index=X_test.index)\n",
    "    return X_scaled_train, X_scaled_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Vert_irreg_right_rail\"\n",
    "\n",
    "y = data[target]\n",
    "X = data.drop(columns=target)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = create_scaled_dataset(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RegModels(modo=\"fit\", X_trainS=X_train, X_testS=X_test, y_trainS=y_train, y_testS=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minhaLista = {'Lasso': 20,\n",
    "              'Random_Forest':  5,\n",
    "              'Elastic_Net':  5,\n",
    "              \n",
    "              'Ada_Boost':  4,\n",
    "              'Ridge':  20,\n",
    "              'XGBR': 8,\n",
    "              'Extra_Trees': 10,\n",
    "              'Cat_Boost': 4,\n",
    "              'Light_Boost': 4,\n",
    "              'KNN_Regressor': 5,\n",
    "              'SGD_Reg': 6\n",
    "              }\n",
    "\n",
    "# minhaLista ={'KNN_Regressor': 4}\n",
    "\n",
    "\n",
    "# reg.fit_models(minhaLista)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:28:25,657]\u001b[0m A new study created in memory with name: no-name-fa5ff846-6eda-45be-a51a-25b9d0b27736\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:25,767]\u001b[0m Trial 0 finished with value: 0.3853278123932964 and parameters: {'alpha': 0.9470112605535648}. Best is trial 0 with value: 0.3853278123932964.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing model Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:28:25,937]\u001b[0m Trial 1 finished with value: 0.47301700326400853 and parameters: {'alpha': 0.5155905210766559}. Best is trial 1 with value: 0.47301700326400853.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:26,132]\u001b[0m Trial 2 finished with value: 0.45167192301580705 and parameters: {'alpha': 0.6018665209984807}. Best is trial 1 with value: 0.47301700326400853.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:26,358]\u001b[0m Trial 3 finished with value: 0.5077112558571978 and parameters: {'alpha': 0.3864942769630606}. Best is trial 3 with value: 0.5077112558571978.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:26,543]\u001b[0m Trial 4 finished with value: 0.4196572276608066 and parameters: {'alpha': 0.7712186256231571}. Best is trial 3 with value: 0.5077112558571978.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:26,786]\u001b[0m Trial 5 finished with value: 0.4730034099592597 and parameters: {'alpha': 0.5156500146652365}. Best is trial 3 with value: 0.5077112558571978.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:27,008]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:27,221]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:27,437]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:27,623]\u001b[0m Trial 9 finished with value: 0.47164828459428465 and parameters: {'alpha': 0.5215475769336451}. Best is trial 3 with value: 0.5077112558571978.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:28,280]\u001b[0m Trial 10 finished with value: 0.5759314537951702 and parameters: {'alpha': 0.13238621896696762}. Best is trial 10 with value: 0.5759314537951702.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:28,702]\u001b[0m Trial 11 finished with value: 0.5752524625835451 and parameters: {'alpha': 0.1360994223421027}. Best is trial 10 with value: 0.5759314537951702.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:29,136]\u001b[0m Trial 12 finished with value: 0.580417322303694 and parameters: {'alpha': 0.10514945436191249}. Best is trial 12 with value: 0.580417322303694.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:29,489]\u001b[0m Trial 13 finished with value: 0.5735009490565719 and parameters: {'alpha': 0.1452556121328008}. Best is trial 12 with value: 0.580417322303694.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:29,677]\u001b[0m Trial 14 finished with value: 0.529547431206943 and parameters: {'alpha': 0.3067321277412663}. Best is trial 12 with value: 0.580417322303694.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:30,074]\u001b[0m Trial 15 finished with value: 0.5499895474109902 and parameters: {'alpha': 0.2382426314959189}. Best is trial 12 with value: 0.580417322303694.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:30,889]\u001b[0m Trial 16 finished with value: 0.5809191575482663 and parameters: {'alpha': 0.10170797067436921}. Best is trial 16 with value: 0.5809191575482663.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:31,241]\u001b[0m Trial 17 finished with value: 0.5455415231690202 and parameters: {'alpha': 0.2543509289159536}. Best is trial 16 with value: 0.5809191575482663.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:31,553]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:32,022]\u001b[0m Trial 19 finished with value: 0.562671622917915 and parameters: {'alpha': 0.19265484021418106}. Best is trial 16 with value: 0.5809191575482663.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:28:32,041]\u001b[0m A new study created in memory with name: no-name-aeec0e86-36ba-4f82-b80c-037c393b2169\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=16, values=[0.5809191575482663], datetime_start=datetime.datetime(2021, 8, 17, 12, 28, 30, 76060), datetime_complete=datetime.datetime(2021, 8, 17, 12, 28, 30, 889462), params={'alpha': 0.10170797067436921}, distributions={'alpha': UniformDistribution(high=1.0, low=0.1)}, user_attrs={'best_model': Lasso(alpha=0.10170797067436921)}, system_attrs={}, intermediate_values={0: 0.5809191575482663}, trial_id=16, state=TrialState.COMPLETE, value=None)\n",
      "\n",
      "\n",
      "Model concluded:  Lasso(alpha=0.10170797067436921) saved as 'Lasso.sav' \n",
      " \n",
      "Optimizing model Random_Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:28:50,049]\u001b[0m Trial 0 finished with value: 0.7946417317818742 and parameters: {'n_estimators': 189, 'max_depth': 14, 'leaf': 4, 'samples_split': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7946417317818742.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:29:46,508]\u001b[0m Trial 1 finished with value: 0.8545662453015644 and parameters: {'n_estimators': 145, 'max_depth': 37, 'leaf': 2, 'samples_split': 10, 'max_features': 20}. Best is trial 1 with value: 0.8545662453015644.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:32:26,766]\u001b[0m Trial 2 finished with value: 0.8539354223084676 and parameters: {'n_estimators': 282, 'max_depth': 43, 'leaf': 4, 'samples_split': 5, 'max_features': 30}. Best is trial 1 with value: 0.8545662453015644.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:34:08,330]\u001b[0m Trial 3 finished with value: 0.8037213532684565 and parameters: {'n_estimators': 330, 'max_depth': 13, 'leaf': 4, 'samples_split': 2, 'max_features': 20}. Best is trial 1 with value: 0.8545662453015644.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:34:48,912]\u001b[0m Trial 4 finished with value: 0.8397620727536665 and parameters: {'n_estimators': 216, 'max_depth': 31, 'leaf': 4, 'samples_split': 10, 'max_features': 10}. Best is trial 1 with value: 0.8545662453015644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=1, values=[0.8545662453015644], datetime_start=datetime.datetime(2021, 8, 17, 12, 28, 50, 187516), datetime_complete=datetime.datetime(2021, 8, 17, 12, 29, 46, 242521), params={'n_estimators': 145, 'max_depth': 37, 'leaf': 2, 'samples_split': 10, 'max_features': 20}, distributions={'n_estimators': IntUniformDistribution(high=500, low=100, step=1), 'max_depth': IntUniformDistribution(high=50, low=10, step=1), 'leaf': CategoricalDistribution(choices=(1, 2, 4)), 'samples_split': CategoricalDistribution(choices=(2, 5, 10)), 'max_features': CategoricalDistribution(choices=('auto', 'sqrt', 'log2', None, 30, 25, 20, 15, 10))}, user_attrs={'best_model': RandomForestRegressor(max_depth=37, max_features=20, min_samples_leaf=2,\n",
      "                      min_samples_split=10, n_estimators=145, n_jobs=-1)}, system_attrs={}, intermediate_values={0: 0.8545662453015644}, trial_id=1, state=TrialState.COMPLETE, value=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:34:50,172]\u001b[0m A new study created in memory with name: no-name-b9e02fbd-124f-43a5-924e-0b556f8e7096\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model concluded:  RandomForestRegressor(max_depth=37, max_features=20, min_samples_leaf=2,\n",
      "                      min_samples_split=10, n_estimators=145, n_jobs=-1) saved as 'Random_Forest.sav' \n",
      " \n",
      "Optimizing model Elastic_Net\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:34:50,553]\u001b[0m Trial 0 finished with value: 0.556547805132362 and parameters: {'alpha': 0.2551493269267231, 'l1_ratio': 0.3938808171063646}. Best is trial 0 with value: 0.556547805132362.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:34:50,781]\u001b[0m Trial 1 finished with value: 0.4336267937349496 and parameters: {'alpha': 0.8715929834879861, 'l1_ratio': 0.6087705477686428}. Best is trial 0 with value: 0.556547805132362.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:34:51,261]\u001b[0m Trial 2 finished with value: 0.5615471307896625 and parameters: {'alpha': 0.22794173238627458, 'l1_ratio': 0.22513149396787974}. Best is trial 2 with value: 0.5615471307896625.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:34:51,636]\u001b[0m Trial 3 finished with value: 0.5366439642319005 and parameters: {'alpha': 0.3578989134114494, 'l1_ratio': 0.5285640150867255}. Best is trial 2 with value: 0.5615471307896625.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:34:52,282]\u001b[0m Trial 4 finished with value: 0.46487370934223904 and parameters: {'alpha': 0.6116424265266104, 'l1_ratio': 0.783998661118216}. Best is trial 2 with value: 0.5615471307896625.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:34:52,302]\u001b[0m A new study created in memory with name: no-name-ed7b0116-efba-42bb-a7ba-3d662bb9f49d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=2, values=[0.5615471307896625], datetime_start=datetime.datetime(2021, 8, 17, 12, 34, 50, 786166), datetime_complete=datetime.datetime(2021, 8, 17, 12, 34, 51, 261182), params={'alpha': 0.22794173238627458, 'l1_ratio': 0.22513149396787974}, distributions={'alpha': UniformDistribution(high=1.0, low=0.1), 'l1_ratio': UniformDistribution(high=1.0, low=0.1)}, user_attrs={'best_model': ElasticNet(alpha=0.22794173238627458, l1_ratio=0.22513149396787974)}, system_attrs={}, intermediate_values={0: 0.5615471307896625}, trial_id=2, state=TrialState.COMPLETE, value=None)\n",
      "\n",
      "\n",
      "Model concluded:  ElasticNet(alpha=0.22794173238627458, l1_ratio=0.22513149396787974) saved as 'Elastic_Net.sav' \n",
      " \n",
      "Optimizing model Ada_Boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:38:24,690]\u001b[0m Trial 0 finished with value: 0.58520182174762 and parameters: {'n_estimators': 702, 'random_state': 38, 'learning_rate': 0.1368787740295723, 'loss': 'linear'}. Best is trial 0 with value: 0.58520182174762.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:41:34,073]\u001b[0m Trial 1 finished with value: 0.6093464872910808 and parameters: {'n_estimators': 885, 'random_state': 30, 'learning_rate': 0.5235334209184086, 'loss': 'square'}. Best is trial 1 with value: 0.6093464872910808.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:41:48,684]\u001b[0m Trial 2 finished with value: 0.45454370448772763 and parameters: {'n_estimators': 25, 'random_state': 30, 'learning_rate': 0.11338545526919955, 'loss': 'linear'}. Best is trial 1 with value: 0.6093464872910808.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:35,750]\u001b[0m Trial 3 finished with value: 0.5964934213784281 and parameters: {'n_estimators': 442, 'random_state': 18, 'learning_rate': 0.5680177058640974, 'loss': 'exponential'}. Best is trial 1 with value: 0.6093464872910808.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,090]\u001b[0m A new study created in memory with name: no-name-215f37a1-e252-450a-9318-05e5cc1a4b6f\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,117]\u001b[0m Trial 0 finished with value: 0.5914127957448458 and parameters: {'alpha': 329.52349995368417}. Best is trial 0 with value: 0.5914127957448458.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,155]\u001b[0m Trial 1 finished with value: 0.5914403155522568 and parameters: {'alpha': 288.69078334668495}. Best is trial 1 with value: 0.5914403155522568.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=1, values=[0.6093464872910808], datetime_start=datetime.datetime(2021, 8, 17, 12, 38, 24, 829437), datetime_complete=datetime.datetime(2021, 8, 17, 12, 41, 33, 884704), params={'n_estimators': 885, 'random_state': 30, 'learning_rate': 0.5235334209184086, 'loss': 'square'}, distributions={'n_estimators': IntUniformDistribution(high=1000, low=10, step=1), 'random_state': IntUniformDistribution(high=50, low=1, step=1), 'learning_rate': UniformDistribution(high=1.0, low=0.01), 'loss': CategoricalDistribution(choices=('linear', 'square', 'exponential'))}, user_attrs={'best_model': AdaBoostRegressor(learning_rate=0.5235334209184086, loss='square',\n",
      "                  n_estimators=885, random_state=30)}, system_attrs={}, intermediate_values={0: 0.6093464872910808}, trial_id=1, state=TrialState.COMPLETE, value=None)\n",
      "\n",
      "\n",
      "Model concluded:  AdaBoostRegressor(learning_rate=0.5235334209184086, loss='square',\n",
      "                  n_estimators=885, random_state=30) saved as 'Ada_Boost.sav' \n",
      " \n",
      "Optimizing model Ridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:43:36,193]\u001b[0m Trial 2 finished with value: 0.5914208982836398 and parameters: {'alpha': 318.1988127205773}. Best is trial 1 with value: 0.5914403155522568.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,224]\u001b[0m Trial 3 finished with value: 0.5914681903970576 and parameters: {'alpha': 236.82357351382757}. Best is trial 3 with value: 0.5914681903970576.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,263]\u001b[0m Trial 4 finished with value: 0.591308648604778 and parameters: {'alpha': 447.50922022367934}. Best is trial 3 with value: 0.5914681903970576.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,299]\u001b[0m Trial 5 finished with value: 0.5914869444033708 and parameters: {'alpha': 37.072396036947445}. Best is trial 5 with value: 0.5914869444033708.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,337]\u001b[0m Trial 6 finished with value: 0.5914983086390858 and parameters: {'alpha': 111.03022385787655}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,377]\u001b[0m Trial 7 finished with value: 0.59147585439875 and parameters: {'alpha': 8.547762368375606}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,417]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,457]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,517]\u001b[0m Trial 10 finished with value: 0.5914978425803468 and parameters: {'alpha': 125.28190872858883}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,560]\u001b[0m Trial 11 finished with value: 0.5914981901277865 and parameters: {'alpha': 117.74664723308784}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,627]\u001b[0m Trial 12 finished with value: 0.5914980353961838 and parameters: {'alpha': 121.71039362895064}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,676]\u001b[0m Trial 13 finished with value: 0.5914976660213138 and parameters: {'alpha': 127.94591875161893}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,727]\u001b[0m Trial 14 finished with value: 0.591485322536928 and parameters: {'alpha': 192.15423961716803}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,787]\u001b[0m Trial 15 finished with value: 0.5914924390419423 and parameters: {'alpha': 57.21236845443357}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,837]\u001b[0m Trial 16 finished with value: 0.5914871901165295 and parameters: {'alpha': 185.87071189979451}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,888]\u001b[0m Trial 17 finished with value: 0.591495023299849 and parameters: {'alpha': 70.3248933711518}. Best is trial 6 with value: 0.5914983086390858.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:36,946]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:37,011]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 12:43:37,025]\u001b[0m A new study created in memory with name: no-name-9b045ee0-91d1-4193-b8ba-bf3d3cd07d90\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=6, values=[0.5914983086390858], datetime_start=datetime.datetime(2021, 8, 17, 12, 43, 36, 305440), datetime_complete=datetime.datetime(2021, 8, 17, 12, 43, 36, 337148), params={'alpha': 111.03022385787655}, distributions={'alpha': UniformDistribution(high=500.0, low=0.1)}, user_attrs={'best_model': Ridge(alpha=111.03022385787655)}, system_attrs={}, intermediate_values={0: 0.5914983086390858}, trial_id=6, state=TrialState.COMPLETE, value=None)\n",
      "\n",
      "\n",
      "Model concluded:  Ridge(alpha=111.03022385787655) saved as 'Ridge.sav' \n",
      " \n",
      "Optimizing model XGBR\n",
      "[12:43:37] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:45:56,210]\u001b[0m Trial 0 finished with value: 0.8470792030644301 and parameters: {'max_depth': 4, 'learning_rate': 0.06139256548005281, 'n_estimators': 489, 'bytree': 0.870758687823932, 'min_child_weight': 8}. Best is trial 0 with value: 0.8470792030644301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:45:56] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:48:04,297]\u001b[0m Trial 1 finished with value: 0.8307659248847858 and parameters: {'max_depth': 6, 'learning_rate': 0.038324981006818186, 'n_estimators': 602, 'bytree': 0.4378530400723394, 'min_child_weight': 4}. Best is trial 0 with value: 0.8470792030644301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:48:04] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:50:37,946]\u001b[0m Trial 2 finished with value: 0.8450883856085772 and parameters: {'max_depth': 3, 'learning_rate': 0.040506521282518346, 'n_estimators': 678, 'bytree': 0.6337019892236848, 'min_child_weight': 5}. Best is trial 0 with value: 0.8470792030644301.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:50:38] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:54:18,040]\u001b[0m Trial 3 finished with value: 0.878701880336841 and parameters: {'max_depth': 8, 'learning_rate': 0.06372904246908097, 'n_estimators': 745, 'bytree': 0.8143126764366898, 'min_child_weight': 9}. Best is trial 3 with value: 0.878701880336841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:54:18] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:55:57,430]\u001b[0m Trial 4 finished with value: 0.8075789764980635 and parameters: {'max_depth': 10, 'learning_rate': 0.050562490530891596, 'n_estimators': 348, 'bytree': 0.7986072646058163, 'min_child_weight': 8}. Best is trial 3 with value: 0.878701880336841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:55:58] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 12:57:52,772]\u001b[0m Trial 5 finished with value: 0.8742285239560281 and parameters: {'max_depth': 6, 'learning_rate': 0.07556751925933611, 'n_estimators': 672, 'bytree': 0.4126774101809423, 'min_child_weight': 5}. Best is trial 3 with value: 0.878701880336841.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:57:53] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:01:05,850]\u001b[0m Trial 6 finished with value: 0.8798890312643725 and parameters: {'max_depth': 4, 'learning_rate': 0.0642276331521847, 'n_estimators': 790, 'bytree': 0.6348710417575942, 'min_child_weight': 5}. Best is trial 6 with value: 0.8798890312643725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:06] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"max_deph\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:03:00,600]\u001b[0m Trial 7 finished with value: 0.8524120692465842 and parameters: {'max_depth': 3, 'learning_rate': 0.06697015450455207, 'n_estimators': 503, 'bytree': 0.537832255657816, 'min_child_weight': 6}. Best is trial 6 with value: 0.8798890312643725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=6, values=[0.8798890312643725], datetime_start=datetime.datetime(2021, 8, 17, 12, 57, 53, 446415), datetime_complete=datetime.datetime(2021, 8, 17, 13, 1, 4, 664622), params={'max_depth': 4, 'learning_rate': 0.0642276331521847, 'n_estimators': 790, 'bytree': 0.6348710417575942, 'min_child_weight': 5}, distributions={'max_depth': IntUniformDistribution(high=10, low=3, step=1), 'learning_rate': UniformDistribution(high=0.1, low=0.01), 'n_estimators': IntUniformDistribution(high=1000, low=100, step=1), 'bytree': UniformDistribution(high=0.9, low=0.1), 'min_child_weight': IntUniformDistribution(high=9, low=4, step=1)}, user_attrs={'best_model': XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.6348710417575942, gamma=0,\n",
      "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.0642276331521847, max_delta_step=0, max_deph=4,\n",
      "             max_depth=6, min_child_weight=5, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=790, n_jobs=4,\n",
      "             num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "             scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "             validate_parameters=1, verbosity=None)}, system_attrs={}, intermediate_values={0: 0.8798890312643725}, trial_id=6, state=TrialState.COMPLETE, value=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:03:02,148]\u001b[0m A new study created in memory with name: no-name-b9dbee8b-347a-4296-aa7c-a2da52caf86c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model concluded:  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.6348710417575942, gamma=0,\n",
      "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.0642276331521847, max_delta_step=0, max_deph=4,\n",
      "             max_depth=6, min_child_weight=5, missing=nan,\n",
      "             monotone_constraints='()', n_estimators=790, n_jobs=4,\n",
      "             num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "             scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "             validate_parameters=1, verbosity=None) saved as 'XGBR.sav' \n",
      " \n",
      "Optimizing model Extra_Trees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:03:22,665]\u001b[0m Trial 0 finished with value: 0.8887411797196474 and parameters: {'n_estimators': 87, 'random_state': 32, 'min_samples_split': 4, 'min_samples_leaf': 2, 'oob_score': False}. Best is trial 0 with value: 0.8887411797196474.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:03:50,559]\u001b[0m Trial 1 finished with value: 0.9023404461579639 and parameters: {'n_estimators': 88, 'random_state': 22, 'min_samples_split': 2, 'min_samples_leaf': 1, 'oob_score': False}. Best is trial 1 with value: 0.9023404461579639.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:04:08,776]\u001b[0m Trial 2 finished with value: 0.8305763659621817 and parameters: {'n_estimators': 90, 'random_state': 27, 'min_samples_split': 4, 'min_samples_leaf': 5, 'oob_score': False}. Best is trial 1 with value: 0.9023404461579639.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:04:23,979]\u001b[0m Trial 3 finished with value: 0.8704768010868198 and parameters: {'n_estimators': 65, 'random_state': 47, 'min_samples_split': 3, 'min_samples_leaf': 3, 'oob_score': True}. Best is trial 1 with value: 0.9023404461579639.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:04:32,219]\u001b[0m Trial 4 finished with value: 0.827993395623204 and parameters: {'n_estimators': 34, 'random_state': 44, 'min_samples_split': 4, 'min_samples_leaf': 5, 'oob_score': False}. Best is trial 1 with value: 0.9023404461579639.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:04:42,763]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:05:02,810]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:05:34,648]\u001b[0m Trial 7 finished with value: 0.8715544010529619 and parameters: {'n_estimators': 95, 'random_state': 35, 'min_samples_split': 2, 'min_samples_leaf': 3, 'oob_score': True}. Best is trial 1 with value: 0.9023404461579639.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:05:53,051]\u001b[0m Trial 8 finished with value: 0.8957795331590277 and parameters: {'n_estimators': 35, 'random_state': 21, 'min_samples_split': 3, 'min_samples_leaf': 1, 'oob_score': False}. Best is trial 1 with value: 0.9023404461579639.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:05:57,489]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=1, values=[0.9023404461579639], datetime_start=datetime.datetime(2021, 8, 17, 13, 3, 22, 936490), datetime_complete=datetime.datetime(2021, 8, 17, 13, 3, 49, 899798), params={'n_estimators': 88, 'random_state': 22, 'min_samples_split': 2, 'min_samples_leaf': 1, 'oob_score': False}, distributions={'n_estimators': IntUniformDistribution(high=100, low=10, step=1), 'random_state': IntUniformDistribution(high=50, low=1, step=1), 'min_samples_split': IntUniformDistribution(high=5, low=2, step=1), 'min_samples_leaf': IntUniformDistribution(high=5, low=1, step=1), 'oob_score': CategoricalDistribution(choices=(True, False))}, user_attrs={'best_model': ExtraTreesRegressor(bootstrap=True, n_estimators=88, random_state=22)}, system_attrs={}, intermediate_values={0: 0.9023404461579639}, trial_id=1, state=TrialState.COMPLETE, value=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:06:07,299]\u001b[0m A new study created in memory with name: no-name-4613acc4-e253-45e7-81da-11301b593435\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model concluded:  ExtraTreesRegressor(bootstrap=True, n_estimators=88, random_state=22) saved as 'Extra_Trees.sav' \n",
      " \n",
      "Optimizing model Cat_Boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:11:16,214]\u001b[0m Trial 0 finished with value: 0.9622646178610941 and parameters: {'n_estimators': 1994, 'depth': 10}. Best is trial 0 with value: 0.9622646178610941.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:14:11,285]\u001b[0m Trial 1 finished with value: 0.9576121952348352 and parameters: {'n_estimators': 1184, 'depth': 10}. Best is trial 0 with value: 0.9622646178610941.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:17:17,954]\u001b[0m Trial 2 finished with value: 0.9597589491025283 and parameters: {'n_estimators': 1413, 'depth': 11}. Best is trial 0 with value: 0.9622646178610941.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:19:26,596]\u001b[0m Trial 3 finished with value: 0.9585020315182061 and parameters: {'n_estimators': 1220, 'depth': 10}. Best is trial 0 with value: 0.9622646178610941.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=0, values=[0.9622646178610941], datetime_start=datetime.datetime(2021, 8, 17, 13, 6, 7, 305461), datetime_complete=datetime.datetime(2021, 8, 17, 13, 11, 10, 310840), params={'n_estimators': 1994, 'depth': 10}, distributions={'n_estimators': IntUniformDistribution(high=2000, low=800, step=1), 'depth': IntUniformDistribution(high=12, low=8, step=1)}, user_attrs={'best_model': <catboost.core.CatBoostRegressor object at 0x7f64b61e3a60>}, system_attrs={}, intermediate_values={0: 0.9622646178610941}, trial_id=0, state=TrialState.COMPLETE, value=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:19:27,615]\u001b[0m A new study created in memory with name: no-name-3ff43780-33b3-4533-bb47-d8842c23c700\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model concluded:  <catboost.core.CatBoostRegressor object at 0x7f64b61e3a60> saved as 'Cat_Boost.sav' \n",
      " \n",
      "Optimizing model Light_Boost\n",
      "[LightGBM] [Warning] Unknown parameter: min_samples_split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:19:45,939]\u001b[0m Trial 0 finished with value: 0.7572379915205765 and parameters: {'min_samples_split': 721, 'max_depth': 14}. Best is trial 0 with value: 0.7572379915205765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "[LightGBM] [Warning] Unknown parameter: min_samples_split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:20:10,961]\u001b[0m Trial 1 finished with value: 0.7576799580109279 and parameters: {'min_samples_split': 290, 'max_depth': 12}. Best is trial 1 with value: 0.7576799580109279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "[LightGBM] [Warning] Unknown parameter: min_samples_split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:20:30,232]\u001b[0m Trial 2 finished with value: 0.7523810373070365 and parameters: {'min_samples_split': 387, 'max_depth': 7}. Best is trial 1 with value: 0.7576799580109279.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "[LightGBM] [Warning] Unknown parameter: min_samples_split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-17 13:20:44,406]\u001b[0m Trial 3 finished with value: 0.7572146406085966 and parameters: {'min_samples_split': 979, 'max_depth': 9}. Best is trial 1 with value: 0.7576799580109279.\u001b[0m\n",
      "\u001b[32m[I 2021-08-17 13:20:44,519]\u001b[0m A new study created in memory with name: no-name-51a04b76-20b8-42af-b58c-8f6f18825b45\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "Finished loading model, total used 100 iterations\n",
      "FrozenTrial(number=1, values=[0.7576799580109279], datetime_start=datetime.datetime(2021, 8, 17, 13, 19, 45, 992550), datetime_complete=datetime.datetime(2021, 8, 17, 13, 20, 10, 916428), params={'min_samples_split': 290, 'max_depth': 12}, distributions={'min_samples_split': IntUniformDistribution(high=1001, low=200, step=1), 'max_depth': IntUniformDistribution(high=14, low=7, step=1)}, user_attrs={'best_model': LGBMRegressor(max_depth=12, min_samples_split=290, random_state=10,\n",
      "              subsample=0.8)}, system_attrs={}, intermediate_values={0: 0.7576799580109279}, trial_id=1, state=TrialState.COMPLETE, value=None)\n",
      "Finished loading model, total used 100 iterations\n",
      "\n",
      "\n",
      "Model concluded:  LGBMRegressor(max_depth=12, min_samples_split=290, random_state=10,\n",
      "              subsample=0.8) saved as 'Light_Boost.sav' \n",
      " \n",
      "Optimizing model KNN_Regressor\n"
     ]
    }
   ],
   "source": [
    "reg.fit_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.models_performace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.stack_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
